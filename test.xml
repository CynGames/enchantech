<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
     xmlns:content="http://purl.org/rss/1.0/modules/content/"
     xmlns:dc="http://purl.org/dc/elements/1.1/"
     xmlns:atom="http://www.w3.org/2005/Atom"
     xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"

>

    <channel>
        <title>Engineering at Meta</title>
        <atom:link href="https://engineering.fb.com/feed/" rel="self" type="application/rss+xml"/>
        <link>https://engineering.fb.com/</link>
        <description>Engineering at Meta Blog</description>
        <lastBuildDate>Thu, 11 Jan 2024 04:49:26 +0000</lastBuildDate>
        <language>en-US</language>
        <sy:updatePeriod>
            hourly
        </sy:updatePeriod>
        <sy:updateFrequency>
            1
        </sy:updateFrequency>
        <generator>https://wordpress.org/?v=6.4.2</generator>
        <site xmlns="com-wordpress:feed-additions:1">147945108</site>
        <item>
            <title>How Meta is advancing GenAI</title>
            <link>https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Thu, 11 Jan 2024 17:00:17 +0000</pubDate>
            <category><![CDATA[AI Research]]></category>
            <category><![CDATA[ML Applications]]></category>
            <category><![CDATA[meta tech podcast]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20873</guid>

            <description><![CDATA[<p>What’s going on with generative AI (GenAI) at Meta? And what does the future have in store? In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) speaks with Devi Parikh, an AI research director at Meta. They cover a wide range of topics, including the history and future of GenAI and the most [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/">How Meta is advancing GenAI</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<p>What’s going on with generative AI (GenAI) at Meta? And what does the future have in store?</p>
<p>In this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (<a href="https://www.threads.net/@passy_">@passy</a>) speaks with Devi Parikh, an AI research director at Meta. They cover a wide range of topics, including the history and future of GenAI and the most interesting research papers that have come out recently.</p>
<p>And, of course, they discuss some of Meta’s latest GenAI innovations, including:</p>
<ul>
<li><a href="https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/" target="_blank" rel="noopener">Audiobox</a>, a foundational model for generating sound and soundscapes using natural language prompts.</li>
<li><a href="https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/" target="_blank" rel="noopener">Emu</a>, Meta’s first foundational model for image generation.</li>
<li><a href="https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/" target="_blank" rel="noopener">Purple Llama</a>, a suite of tools to help developers safely and responsibly deploy GenAI models.</li>
</ul>
<p>Download or listen to the episode below:</p>
<p><iframe style="border: none;" title="Libsyn Player" src="//html5-player.libsyn.com/embed/episode/id/29182733/height/90/theme/custom/thumbnail/yes/direction/forward/render-playlist/no/custom-color/000000/" width="100%" height="90" scrolling="no" allowfullscreen="allowfullscreen"></iframe></p>
<p>You can also find the episode on various podcast platforms:</p>
<p><a href="https://open.spotify.com/episode/417ZV5wibSU7rJYOofFANB" target="_blank" rel="noopener">Spotify</a><br />
<a href="https://pca.st/ot14urbh" target="_blank" rel="noopener">PocketCasts</a><br />
<a href="https://podcasts.apple.com/gb/podcast/advancing-genai-at-meta/id1370910331?i=1000639340717" target="_blank" rel="noopener">Apple Podcasts</a><br />
<a href="https://podcasts.google.com/feed/aHR0cHM6Ly9pbnNpZGVmYWNlYm9va21vYmlsZS5saWJzeW4uY29tL3Jzcw/episode/OGNiMTMwOTktYWY2Ny00YzkxLTgxNDgtMjZiMWM0OGQ1MWYx?sa=X&amp;ved=0CAgQuIEEahcKEwiA9NbNvL6DAxUAAAAAHQAAAAAQLA" target="_blank" rel="noopener">Google Podcasts</a></p>
<p>The <a href="https://insidefacebookmobile.libsyn.com/" target="_blank" rel="noopener">Meta Tech Podcast</a> is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.</p>
<p>Send us feedback on <a href="https://instagram.com/metatechpod" target="_blank" rel="noopener">Instagram</a>, <a href="https://threads.net/@metatechpod" target="_blank" rel="noopener">Threads</a>, or <a href="https://twitter.com/metatechpod" target="_blank" rel="noopener">X</a>.</p>
<p>And if you’re interested in AI career opportunities at Meta visit the <a href="https://www.metacareers.com/" target="_blank" rel="noopener">Meta Careers</a> page.</p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2024/01/11/ml-applications/meta-advancing-genai/">How Meta is advancing GenAI</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20873</post-id>
        </item>
        <item>
            <title>How Meta built the infrastructure for Threads</title>
            <link>https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Tue, 19 Dec 2023 17:01:57 +0000</pubDate>
            <category><![CDATA[Core Infra]]></category>
            <category><![CDATA[Production Engineering]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20851</guid>

            <description><![CDATA[<p>On July 5, 2023, Meta launched Threads, the newest product in our family of apps, to an unprecedented success that saw it garner over 100 million sign ups in its first five days. A small, nimble team of engineers built Threads over the course of only five months of technical work. While the app’s production [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/">How Meta built the infrastructure for Threads</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<p><span style="font-weight: 400;">On July 5, 2023, Meta launched Threads, the newest product in our family of apps, to an unprecedented success that saw it garner </span><a href="https://www.threads.net/@zuck/post/CuhOXGmr74R"><span style="font-weight: 400;">over 100 million sign ups</span></a><span style="font-weight: 400;"> in its first five days.</span></p>
<p><span style="font-weight: 400;">A small,</span><a href="https://engineering.fb.com/2023/09/07/culture/threads-inside-story-metas-newest-social-app/"> <span style="font-weight: 400;">nimble team of engineers built Threads</span></a><span style="font-weight: 400;"> over the course of only five months of technical work. While the app’s production launch had been under consideration for some time, the business finally made the decision and informed the infrastructure teams to prepare for its launch with only two days’ advance notice. The decision was made with full confidence that Meta’s infrastructure teams can deliver based on their past track record and the maturity of the infrastructure. Despite the daunting challenges with minimal lead time, the infrastructure teams supported the app’s rapid growth exceptionally well.</span></p>
<p><span style="font-weight: 400;">The seamless scale that people experienced as they signed up by the millions came on the shoulders of over a decade of infrastructure and product development. This was not infrastructure purposely built for Threads, but that had been built over the course of Meta’s lifetime for many products. It had already been built for scale, growth, performance, and reliability, and it managed to exceed our expectations as Threads grew at a pace that no one could have predicted.</span></p>
<p><span style="font-weight: 400;">A huge amount of infrastructure goes into serving Threads. But, because of space limitations, we will only give examples of two existing components that played an important role:</span> <a href="https://engineering.fb.com/2021/08/06/core-infra/zippydb/" target="_blank" rel="noopener"><span style="font-weight: 400;">ZippyDB</span></a><span style="font-weight: 400;">, our distributed key/value datastore, and</span> <a href="https://engineering.fb.com/2020/08/17/production-engineering/async/" target="_blank" rel="noopener"><span style="font-weight: 400;">Async</span></a><span style="font-weight: 400;">, our aptly named asynchronous serverless function platform.</span></p>
<h2><span style="font-weight: 400;">ZippyDB: Scaling keyspaces for Threads</span></h2>
<p><span style="font-weight: 400;">Let’s zoom in on part of the storage layer, where we leveraged ZippyDB, a distributed key/value database that is run as a fully managed service for engineers to build on. It’s built from the ground up to leverage Meta’s infrastructure, and keyspaces hosted on it can be scaled up and down with relative ease and flexibly placed across any number of data centers. </span><a href="https://engineering.fb.com/2013/06/25/core-infra/tao-the-power-of-the-graph/" target="_blank" rel="noopener"><span style="font-weight: 400;">TAO</span></a><span style="font-weight: 400;">, backed by </span><a href="https://engineering.fb.com/2023/05/16/data-infrastructure/mysql-raft-meta/" target="_blank" rel="noopener"><span style="font-weight: 400;">MySQL</span></a><span style="font-weight: 400;">, is used for our social graph storage – thus you can find Threads posts and replies directly in that stack. ZippyDB is our key/value counterpart to MySQL, the relational part of our online data stack, and is used for counters, feed ranking/state, and search. </span></p>
<p><img fetchpriority="high" decoding="async" class="alignnone size-large" src="https://engineering.fb.com/wp-content/uploads/2021/08/ZippyDb.1.psd.BodyImage1.jpg?resize=1024,576" width="1024" height="576" /></p>
<p><span style="font-weight: 400;">The speed at which we can scale the capacity of a keyspace is made possible by two key features: First, the service runs on a common pool of hardware and is plugged into Meta&#8217;s overall capacity management framework. Once new capacity is allocated to the service, the machines are automatically added to the service’s pool and the load balancer kicks in to move data to the new machines. We can absorb thousands of new machines in a matter of a few hours once they are added to the service. While this is great, it is not enough since the end-to-end time in approving capacity, possibly draining it from other services and adding it to ZippyDB, can still be in order of a couple of days. We need to also be able to absorb a surge on shorter notice.</span></p>
<p><span style="font-weight: 400;">To enable the immediate absorption, we rely on the service architecture’s multi-tenancy and its strong isolation features. This allows for different keyspaces, potentially with complimentary load demands to share the underlying hosts, without worrying about their service level getting impacted when other workloads run hot. There is also slack in the hosts pool due to unused capacity of individual keyspaces as well as buffers for handling disaster recovery events. We can pull levers that shift unused allocations between keyspaces – dipping into any existing slack and letting the hosts run at a higher utilization level to let a keyspace ramp up almost immediately and sustain it over a short interval (a couple of days). All these are simple config changes with tools and automation built around them as they are fairly routine for day-to-day operations.</span></p>
<p><span style="font-weight: 400;">The combined effects of strong multi-tenancy and ability to absorb new hardware makes it possible for the service to scale more or less seamlessly, even in the face of a sudden large new demand.</span></p>
<h2><span style="font-weight: 400;">Optimizing ZippyDB for a product launch</span></h2>
<p><span style="font-weight: 400;">ZippyDB’s resharding protocol allows us to quickly and transparently increase the sharding factor (i.e., horizontal scaling factor) of a ZippyDB use case with zero downtime for clients, all while maintaining full consistency and correctness guarantees. This allows us to rapidly scale out use cases on the critical path of new product launches with zero interruptions to the launch, even if its load increases by 100x.</span></p>
<p><span style="font-weight: 400;">We achieve this by having clients hash their keys to logical shards, which are then mapped to a set of physical shards. When a use case grows and requires resharding, we provision a new set of physical shards and install a new logical-to-physical shard mapping in our clients through live configuration changes without downtime. Using hidden access keys on the server itself, and smart data migration logic in our resharding workers, we are then able to atomically move a logical shard from the original mapping to the new mapping. Once all logical shards have been migrated, resharding is complete and we remove the original mapping.</span></p>
<p><span style="font-weight: 400;">Because scaling up use cases is a critical operation for new product launches, we have invested heavily in our resharding stack to ensure ZippyDB scaling does not block product launches. Specifically, we have designed the resharding stack in a coordinator-worker model so it is horizontally scalable, allowing us to increase resharding speeds when needed, such as during the Threads launch. Additionally, we have developed a set of emergency operator tools to effortlessly deal with sudden use case growth. </span></p>
<p><span style="font-weight: 400;">The combination of these allowed the ZippyDB team to effectively respond to the rapid growth of Threads. Often, when creating new use cases in ZippyDB, we start small initially and then reshard as growth requires. This approach prevents overprovisioning and promotes efficiency in capacity usage. As the viral growth of Threads began, it became evident that we needed to prepare Threads for a 100x growth by proactively performing resharding. With the help of automation tools developed in the past, we completed the resharding just in time as the Threads team opened up the floodgates to traffic at midnight UK time. This enabled delightful user experiences with Threads, even as its user base soared.</span></p>
<h2><span style="font-weight: 400;">Async: Scaling workload execution for Threads</span></h2>
<p><span style="font-weight: 400;">Async (also known as </span><a href="https://dl.acm.org/doi/pdf/10.1145/3600006.3613155"><span style="font-weight: 400;">XFaaS</span></a><span style="font-weight: 400;">) is a serverless function platform capable of deferring computing to off-peak hours, allowing engineers at Meta to reduce their time from solution conception to production deployment. Async currently processes trillions of function calls per day on more than 100,000 servers and can support </span><a href="https://engineering.fb.com/2022/07/27/developer-tools/programming-languages-endorsed-for-server-side-use-at-meta/"><span style="font-weight: 400;">multiple programming languages</span></a><span style="font-weight: 400;">, including HackLang, Python, Haskell, and Erlang. </span></p>
<p><img decoding="async" class="alignnone size-large wp-image-16517" src="https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?w=1024" alt="" width="1024" height="521" srcset="https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg 1920w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=916,466 916w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=768,391 768w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=1024,521 1024w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=1536,782 1536w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=96,49 96w, https://engineering.fb.com/wp-content/uploads/2020/08/Async-Server-2.jpg?resize=192,98 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">The platform abstracts the details of deployment, queueing, scheduling, scaling, and disaster recovery and readiness, so that developers can focus on their core business logic and offload the rest of the heavy lifting to Async. By onboarding their code in this platform, their code automatically inherits hyperscale attributes. Scalability is not the only key feature of Async. Code uploaded to the platform also inherits guarantees on execution with configurable retries, time for delivery, rate limits, and capacity accountability.</span></p>
<p><span style="font-weight: 400;">The workloads commonly executed on Async are those that do not require blocking an active user&#8217;s experience with a product and can be performed anywhere from a few seconds to several hours after a user&#8217;s action. Async played a critical role in offering users the ability to build community quickly by choosing to follow people on Threads that they already follow on Instagram. Specifically, when a new user joins Threads and chooses to follow the same set of people they do on Instagram, the computationally expensive operation of executing the user’s request to follow the same social graph in Threads is conducted via Async in a scalable manner, which avoids blocking or negatively impacting the user&#8217;s onboarding experience. </span></p>
<p><span style="font-weight: 400;">Doing this for 100 million users in five days required significant processing power. Moreover, many celebrities joined Threads, and when that happened millions of people could be queued up to follow them. Both this operation and the corresponding notifications also occurred in Async, enabling scalable operations in the face of a large number of users.</span></p>
<p><span style="font-weight: 400;">While the volume of Async jobs generated from the rapid Threads user onboarding was several orders of magnitude higher than our initial expectations, Async gracefully absorbed the increased load and queued them for controlled execution. </span><span style="font-weight: 400;">Specifically, the execution was managed within rate limits, which ensured that we were sending notifications and allowing people to make connections in a timely manner without overloading the downstream services that receive traffic from these Async jobs. Async automatically adjusted the flow of execution to match its capacity as well as the capacity of dependent services, such as the social graph database, all without manual intervention from either Threads engineers or infrastructure engineers.</span></p>
<h2><span style="font-weight: 400;">Where infrastructure and culture meet</span></h2>
<p><span style="font-weight: 400;">Threads’ swift development within a mere five months of technical work underscores the strengths of Meta&#8217;s infrastructure and engineering culture. Meta&#8217;s products leverage a shared infrastructure that has withstood the test of time, empowering product teams to move fast and rapidly scale successful products. The infrastructure boasts a high level of automation, ensuring that, except for efforts to secure capacity on short notice, the automatic redistribution, load balancing, and scaling up of workloads occurred smoothly and transparently. </span><span style="font-weight: 400;">Meta thrives on a move-fast engineering culture, wherein engineers take strong ownership and collaborate seamlessly to accomplish a large shared goal, with efficient processes that would take a typical organization months to coordinate. As an example, our</span><a href="https://atscaleconference.com/videos/metas-sev-culture-how-todays-sevs-create-tomorrows-reliability/"> <span style="font-weight: 400;">SEV incident-management culture</span></a><span style="font-weight: 400;"> has been an important tool in getting the right visibility, focus, and action in places where we all need to coordinate and move fast. Overall, these factors combined to ensure the success of the Threads launch.</span></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/">How Meta built the infrastructure for Threads</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20851</post-id>
        </item>
        <item>
            <title>AI debugging at Meta with HawkEye</title>
            <link>https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Tue, 19 Dec 2023 17:00:52 +0000</pubDate>
            <category><![CDATA[Data Infrastructure]]></category>
            <category><![CDATA[DevInfra]]></category>
            <category><![CDATA[ML Applications]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20829</guid>

            <description><![CDATA[<p>HawkEye is the powerful toolkit used internally at Meta for monitoring, observability, and debuggability of the end-to-end machine learning (ML) workflow that powers ML-based products. HawkEye supports recommendation and ranking models across several products at Meta. Over the past two years, it has facilitated order of magnitude improvements in the time spent debugging production issues. [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/">AI debugging at Meta with HawkEye</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">HawkEye is the powerful toolkit used internally at Meta for monitoring, observability, and debuggability of the end-to-end machine learning (ML) workflow that powers ML-based products.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">HawkEye supports recommendation and ranking models across several products at Meta. Over the past two years, it has facilitated order of magnitude improvements in the time spent debugging production issues.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">In this post, we will provide an overview of the end-to-end debugging workflows supported by HawkEye, components of the system, and the product surface for Meta product and monetization teams to debug AI model and feature issues.</span></li>
</ul>
<p><span style="font-weight: 400;">Many of Meta’s products and services leverage ML for various tasks such as recommendations, understanding content, and generating content. Workflows to productionize ML models include data pipelines to get the information needed to train the models, training workflows to build and improve the models over time, evaluation systems to test the models, and inference workflows to actually use the models in Meta&#8217;s products. At any point in time multiple versions (snapshots) of a model could be hosted as A/B experiments to test their performance and accuracy.</span></p>
<p><span style="font-weight: 400;">Ensuring the robustness of predictions made by models is crucial for providing engaging user experiences and effective monetization. However, several factors can affect the accuracy of these predictions, such as the distribution of data used for training, inference-time inputs, the (hyper)parameters of the model, and the systems configuration. Identifying the root cause of any issue is a complex problem, especially given the scale of Meta&#8217;s models and data.</span></p>
<p><span style="font-weight: 400;">At Meta, we created the Prediction Robustness program to innovate on tools and services to ensure the quality of Meta products relying on ML model predictions. HawkEye is the powerful toolkit we built as a part of this effort for the monitoring, observability, and debuggability of ML-based products. HawkEye includes infrastructure for continuously collecting data on serving and training models, data generation, and analysis components for mining root causes. It supports UX workflows for guided exploration, investigation, and initiating mitigation actions.</span></p>
<figure id="attachment_20840" aria-describedby="caption-attachment-20840" style="width: 916px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="wp-image-20840 size-medium" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?w=916" alt="" width="916" height="216" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png 1498w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?resize=916,216 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?resize=768,181 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?resize=1024,242 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?resize=96,23 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image1.png?resize=192,45 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20840" class="wp-caption-text">HawkEye’s components.</figcaption></figure>
<h2>Our approach to AI debugging</h2>
<p><span style="font-weight: 400;">Prior to HawkEye’s development, identifying and resolving issues in production workflows for features and models required specialized knowledge and familiarity with the processes and telemetry involved. Additionally, it required substantial coordination across different organizations. To address these challenges, model and feature on-call engineers, who debug models and features, would utilize shared notebooks and code to do root cause analyses for small parts of the overall debugging process.</span></p>
<p><span style="font-weight: 400;">HawkEye implements a decision tree that streamlines this process while building the necessary components for continuous instrumentation and analysis layers to build the tree. HawkEye enables users to efficiently navigate the decision tree and quickly identify the root cause of complex issues. As a result, HawkEye has significantly reduced the time spent on debugging complex production issues, simplified operational workflows, and enabled non-experts to triage complex issues with minimal coordination and assistance.</span></p>
<figure id="attachment_20841" aria-describedby="caption-attachment-20841" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20841" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=916,165 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=1536,277 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image2.png?resize=192,35 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20841" class="wp-caption-text">HawkEye’s debugging workflows.</figcaption></figure>
<p><span style="font-weight: 400;">Operational debugging workflows typically begin with an alert triggered by a problem with a key metric for a product, or an anomaly in a model or feature (at serving or training time). Examples of detection mechanisms include model validation failures, model explosions in gradient/loss, prediction anomalies, and shifts in feature distribution. It&#8217;s worth noting that a top line anomaly debugging workflow may encompass all of the other workflows. HawkEye supports this workflow by providing guided exploration surfaces layered on top of the necessary components, allowing users to efficiently investigate and resolve issues.</span></p>
<h2>Isolating top-line product issues to model snapshots</h2>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20842" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image3.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">The initial step in investigating an anomaly in a product&#8217;s top-line metrics is to pinpoint the specific serving model, infrastructure, or traffic-related factors responsible for the degradation. This can be difficult because multiple models might be used for different product and user segments, A/B experiments, or composed predictions. Additionally, model traffic distribution can vary as experiments are scaled up or down.</span></p>
<p><span style="font-weight: 400;">HawkEye performs analysis and detection to identify models with prediction degradation correlated with the anomaly in the top-line metrics across all experiments. This enables on-call personnel to assess the quality of predictions for all models powering the affected product and/or user segment. </span></p>
<figure id="attachment_20843" aria-describedby="caption-attachment-20843" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20843" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?w=1024" alt="" width="1024" height="555" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=916,497 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=768,416 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=1024,555 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=1536,833 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=96,52 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image4.png?resize=192,104 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20843" class="wp-caption-text">Product anomaly to model isolation.</figcaption></figure>
<p><span style="font-weight: 400;">Next, HawkEye enables on-calls to correlate top-line degradation with a timeline of snapshot rollouts for each model. The outcome from this step is typically a small set of suspect model snapshots in serving.</span></p>
<figure id="attachment_20830" aria-describedby="caption-attachment-20830" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20830" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?w=1024" alt="" width="1024" height="486" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=916,434 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=768,364 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=1024,486 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=1536,728 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=96,46 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image5.png?resize=192,91 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20830" class="wp-caption-text">Model anomaly to snapshot isolation.</figcaption></figure>
<p><span style="font-weight: 400;">Once a model has been isolated, the next step is to determine if the root cause is a </span><i><span style="font-weight: 400;">bad</span></i><span style="font-weight: 400;"> snapshot. Rolling back to an older snapshot can provide immediate mitigation, but outdated models can also lead to prediction robustness issues that deteriorate over time. It is essential to identify the underlying cause of a bad snapshot, such as training data or model problems.</span></p>
<h2>Isolating prediction anomalies to features</h2>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20831" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image6.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">Serving models can consume thousands of features (each with their own data pipelines) at very high request rates. At such scales, identifying the list of features responsible for prediction anomalies requires real-time analyses of model inputs and outputs. HawkEye uses model explainability and feature importance algorithms to localize prediction changes to subsets of features.</span></p>
<p><span style="font-weight: 400;">HawkEye samples model inputs and predictions for each serving model and computes correlations between time-aggregated feature distributions and prediction distributions to identify significant correlation structure during periods of degradation. This allows for real-time feature isolation.</span></p>
<p><span style="font-weight: 400;">In addition, HawkEye computes feature importance changes using feature ablation algorithms on serving model snapshots, which provides a stronger signal than correlational analysis but requires longer processing times due to the need to cover the entire feature distribution hyperspace. When the change in feature importance is significant for a particular feature, it indicates that the feature has a different impact on model predictions in the current snapshot compared to previous snapshots and is a candidate for investigation.</span></p>
<p><span style="font-weight: 400;">HawkEye presents the on-call with a ranked list of features (or the absence thereof) responsible for prediction anomalies, derived from its model explainability and feature importance analyses. This approach has reduced the time from triage to serving features by several orders of magnitude.</span></p>
<figure id="attachment_20832" aria-describedby="caption-attachment-20832" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20832" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?w=1024" alt="" width="1024" height="605" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=916,542 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=768,454 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=1024,605 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=1536,908 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=96,57 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image7.png?resize=192,114 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20832" class="wp-caption-text">Model to feature isolation.</figcaption></figure>
<h2>Isolating upstream causes of feature issues</h2>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20833" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image8.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">A large-scale data processing setup consists of complex data transformation pipelines (which may include real-time joins), which create features, which are then stored in systems belonging to multiple infrastructure teams. HawkEye tracks the lineage of upstream data and pipelines, keeping track of statistical information about each feature&#8217;s upstream data dependencies and transformations that have occurred, including changes to transform code or configurations.</span></p>
<p><span style="font-weight: 400;">HawkEye facilitates root-cause analysis of feature problems through a visual workflow that moves upstream along the lineage graph and examines the statistics of related lineage nodes. This helps pinpoint the source of a problematic feature by correlating it with upstream data statistics along with a measure of confidence. Without relying on a model anomaly, HawkEye enables investigations into feature upstream issues from feature health alerts, enabling engineers to detect and correct faults before they impact the live models.</span></p>
<figure id="attachment_20834" aria-describedby="caption-attachment-20834" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20834" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?w=1024" alt="" width="1024" height="606" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=916,542 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=768,454 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=1024,606 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=1536,909 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=96,57 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image9.png?resize=192,114 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20834" class="wp-caption-text">Feature upstream debugging.</figcaption></figure>
<h2>Diagnosing model snapshots</h2>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20835" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image10.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">Sometimes prediction errors are not due to the features, but result from issues with the model itself, which are a result of model training (e.g., hyperparameter-, architectural-, or training data-related). To determine whether there is an issue with the model, HawkEye compares the model&#8217;s current snapshot (specifically, its weights and biases) with previous snapshots that have been operationally stable. In normal scenarios, model parameters across snapshots show some degree of stationarity. However, significant differences indicate problems with either the training data or loss divergence (e.g., loss or gradient explosion) in the bad snapshot.</span></p>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20836" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image11.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">When a snapshot is published, HawkEye also runs inference on the snapshot using recent feature data, and captures neuron output and activation tensors in the forward pass. If it finds outputs that are NaNs or extreme values, it uses the activations to walk upstream and downstream on the model graph to associate the problem with feature(s) at the input layer, or the effect on predictions at the output layer. Walking the model graph also enables finding opportunities to improve model architecture (e.g., adding layer normalization, clipping, or other operators).</span></p>
<p><span style="font-weight: 400;">Analyzing and walking through the large model graph helps identify the cause of bad snapshots quickly and proactively. HawkEye provides model graph visualization with tensor level stats, along with graph walking visualizations. Lowering and post-quantization analyses, as well as analyses while training, are beyond the scope of this discussion.</span></p>
<figure id="attachment_20837" aria-describedby="caption-attachment-20837" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20837" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?w=1024" alt="" width="1024" height="608" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=916,543 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=768,456 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=1024,608 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=1536,911 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=96,57 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image12.png?resize=192,114 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20837" class="wp-caption-text">Model snapshot debugging.</figcaption></figure>
<h2>Diagnosing training data issues</h2>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20838" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?w=1024" alt="" width="1024" height="184" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png 1181w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?resize=916,164 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?resize=768,138 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?resize=1024,184 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?resize=96,17 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image13.png?resize=192,34 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">HawkEye enables on-calls to easily navigate from a suspect snapshot to the training pipeline that produced it and inspect statistical issues with training data (at a partition granularity) and training-time metrics (e.g., learning curve, loss function evolution). This feature enables the on-call to identify data drift between training and serving label distributions, and anomalies with labels (e.g., label imbalance). Such issues can happen for several hard-to-diagnose reasons, ranging from the complex data pipelines behind training data, to data corruptions. HawkEye provides observability into the upstream data pipelines and their health and helps locate the root cause of bad training data. It also provides quick mitigation capabilities, such as pausing affected pipelines if upstream data is bad, and prevents further production impact due to training snapshots.</span></p>
<figure id="attachment_20839" aria-describedby="caption-attachment-20839" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20839" src="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?w=1024" alt="" width="1024" height="607" srcset="https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png 1999w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=916,543 916w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=768,455 768w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=1024,607 1024w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=1536,910 1536w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=96,57 96w, https://engineering.fb.com/wp-content/uploads/2023/12/HawkEye_image14.png?resize=192,114 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20839" class="wp-caption-text">Training data debugging.</figcaption></figure>
<h2>Next steps for HawkEye</h2>
<p><span style="font-weight: 400;">Moving forward, we will continue to keep track of emerging root causes in production issues, adding detailed analyses to HawkEye workflows and the product surface. We are also piloting extensibility features in the product and backend components, so that product teams can add generic and specialized debugging workflows to HawkEye, while the community benefits from some of these workflows.</span></p>
<h2><em>Acknowledgements</em></h2>
<p><i><span style="font-weight: 400;">We would like to thank all current and past members of the HawkEye team and its partners that helped make this effort a success. A special thank you to Girish Vaitheeswaran, Atul Goyal, YJ Liu, Shiblee Sadik, Peng Sun, Adwait Tumbde, Karl Gyllstrom, Sean Lee, Dajian Li, Yu Quan, Robin Tafel, Ankit Asthana, Gautam Shanbhag, and Prabhakar Goyal.</span></i></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/19/data-infrastructure/hawkeye-ai-debugging-meta/">AI debugging at Meta with HawkEye</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20829</post-id>
        </item>
        <item>
            <title>Building end-to-end security for Messenger</title>
            <link>https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Thu, 07 Dec 2023 02:00:08 +0000</pubDate>
            <category><![CDATA[Security]]></category>
            <category><![CDATA[Messenger]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20811</guid>

            <description><![CDATA[<p>We are beginning to upgrade people’s personal conversations on Messenger to use end-to-end encryption (E2EE) by default. Meta is publishing two technical white papers on end-to-end encryption: Our Messenger end-to-end encryption whitepaper describes the core cryptographic protocol for transmitting messages between clients. The Labyrinth encrypted storage protocol whitepaper explains our protocol for end-to-end encrypting stored [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/">Building end-to-end security for Messenger</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<ul>
<li aria-level="1"><span style="font-weight: 400;">We are beginning to upgrade people’s personal conversations on Messenger to use end-to-end encryption (E2EE) by default.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Meta is publishing two technical white papers on end-to-end encryption:</span>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Our <a href="https://engineering.fb.com/wp-content/uploads/2023/12/MessengerEnd-to-EndEncryptionOverview_12-6-2023.pdf" target="_blank" rel="noopener">Messenger end-to-end encryption whitepaper </a>describes the core cryptographic protocol for transmitting messages between clients.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The <a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf" target="_blank" rel="noopener">Labyrinth encrypted storage protocol whitepaper</a> explains our protocol for end-to-end encrypting stored messaging history between devices on a user’s account.</span></li>
</ul>
</li>
</ul>
<p><span style="font-weight: 400;">Today, we&#8217;re announcing that we&#8217;ve begun to upgrade people’s personal conversations on Messenger to use E2EE by default. Our aim is to ensure that everyone’s personal messages on Messenger can only be accessed by the sender and the intended recipients, and that everyone can be sure the messages they receive are from an authentic sender.</span></p>
<p><span style="font-weight: 400;">This is the most significant milestone yet for this project, which began in earnest after </span><a href="https://www.facebook.com/notes/2420600258234172/" target="_blank" rel="noopener"><span style="font-weight: 400;">Mark Zuckerberg outlined his vision for it in 2019</span></a><span style="font-weight: 400;">. Bringing E2EE to Messenger has been a complex process, with every feature and product goal revealing further challenges that required careful consideration.</span></p>
<p><span style="font-weight: 400;">Enabling E2EE on Messenger meant fundamentally rebuilding many aspects of the application protocols to improve privacy, security, and safety while simultaneously maintaining the features that have made Messenger so popular. </span></p>
<h2><span style="font-weight: 400;">Why we’re bringing E2EE to Messenger</span></h2>
<p><span style="font-weight: 400;">Messenger first</span> <a href="https://about.fb.com/news/2016/07/messenger-starts-testing-end-to-end-encryption-with-secret-conversations/" target="_blank" rel="noopener"><span style="font-weight: 400;">built end-to-end encrypted chats in 2016 </span></a><span style="font-weight: 400;">as a feature called Secret Conversations. Since then, we’ve learned a great deal in regards to rolling out E2EE for a wider user base. For example, we recently published an updated</span> <span style="font-weight: 400;">white paper, &#8220;</span><a href="https://messengernews.fb.com/wp-content/uploads/2021/12/Metas-approach-to-safer-private-messaging-on-Messenger-and-Instagram-DMs-Sep-23.pdf" target="_blank" rel="noopener">Meta’s Approach to Safer Private Messaging on Messenger and Instagram Direct Messaging</a>,&#8221; t<span style="font-weight: 400;">hat sets out the industry-leading safety systems and tools available on Messenger.</span></p>
<p><span style="font-weight: 400;">End-to-end encryption isn’t about the technology at its core. It&#8217;s about protecting people’s communications, so they can feel safe expressing themselves with their friends and loved ones. To  achieve this, we typically focus on two aims:</span></p>
<ol>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Only the sender and recipients of an E2EE message can see its contents.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Nobody (not even Meta) should be able to forge messages to appear to have been sent from someone they weren’t.</span></li>
</ol>
<p><span style="font-weight: 400;">In other words, the aim is that only you and the people you’re corresponding with can read your messages – not even the app’s provider (in this case, Meta) could interfere with their contents – and you can be confident in who sent the messages. </span></p>
<h2><span style="font-weight: 400;">Understanding these goals</span></h2>
<p><span style="font-weight: 400;">These two aims are broad. However, when we reflect on our approach to addressing them, they end up breaking down into eight overlapping concepts that we believe achieve a cohesive approach to meaningful E2EE: </span></p>
<h3><span style="font-weight: 400;">1. Confidentiality in transit</span></h3>
<p><span style="font-weight: 400;">Message contents are authentically and securely transmitted between your devices and those of the people you’re talking to. This is, perhaps, the primary goal of E2EE, and is where much E2EE research and design work is targeted, such as the Signal protocol we use in our products (such as WhatsApp, Messenger, and Instagram Direct), or the </span><a href="https://datatracker.ietf.org/doc/rfc9420/" target="_blank" rel="noopener"><span style="font-weight: 400;">IETF’s Messaging Layer Security protocol</span></a><span style="font-weight: 400;">, which we helped to design and was recently standardized.</span></p>
<h3><span style="font-weight: 400;">2. Confidentiality in storage</span></h3>
<p><span style="font-weight: 400;">Typically, E2EE messaging services rely on local storage and encryption keys to secure encrypted messages. Messenger, however, has a long history of storing people’s messages for them so that they can access them whenever they need without having to store them locally. That’s why we’ve designed a server-based solution where encrypted messages can be stored on Meta’s servers while only being readable using encryption keys under the user’s control. </span></p>
<h3><span style="font-weight: 400;">3. Control over endpoints</span></h3>
<p><span style="font-weight: 400;">For something to be “end-to-end encrypted,” it is necessary to have a notion of what the “ends” are. For an E2EE messaging app this means that users should have the ability to verify and manage their set of endpoint devices that are receiving their messages, as well as visibility into when this set of devices changes.</span></p>
<h3><span style="font-weight: 400;">4. Private feature designs</span></h3>
<p><span style="font-weight: 400;">Product features in an E2EE setting typically need to be designed to function in a device-to-device manner, without ever relying on a third party having access to message content. This </span><a href="https://messengernews.fb.com/2023/08/22/expanding-testing-for-end-to-end-encryption-on-messenger/"><span style="font-weight: 400;">was a significant effort for Messenger</span></a><span style="font-weight: 400;">, as much of its functionality has historically relied on server-side processing, with certain features difficult or impossible to exactly match with message content being limited to the devices.</span></p>
<h3><span style="font-weight: 400;">5. Logging limitations</span></h3>
<p><span style="font-weight: 400;">Maintaining the confidentiality of message content extends to avoiding accidentally leaking it back to us in telemetry. In a product of Messenger’s scale, complexity, and iteration speed, this creates particular challenges as telemetry is vital in ensuring that the product is working well for people, and in debugging when things go wrong.</span></p>
<h3><span style="font-weight: 400;">6. Application security</span></h3>
<p><span style="font-weight: 400;">It’s a common saying that, “You can’t have privacy without security,” and this is absolutely true in the end-to-end encrypted domain. Security is important for any consumer product, but E2EE exacerbates the challenges in two important ways: it reduces the provider’s ability to protect the user from attacks, and, in fact, it expands the threat model to include the service provider itself. Our security team is keenly aware of these challenges and works closely with product teams to secure design and implementation of E2EE functionality. For example, we’ve been working to improve the memory safety of our apps; and our E2EE surfaces are covered by our <a href="https://www.facebook.com/whitehat" target="_blank" rel="noopener">bug bounty program</a>.</span></p>
<h3><span style="font-weight: 400;">7. Being deliberate about what&#8217;s being protected</span></h3>
<p><span style="font-weight: 400;">E2EE protects message content. However, this is a complex term to define, and, while certain things are relatively clear – such as the strings contained in a text message, or a photograph sent from your camera roll – in a sufficiently complex messaging application, it turns out there&#8217;s a surprisingly large grey area.  Our focus is on determining the appropriate boundaries, ensuring that we remain true to our commitments, setting the correct user expectations, and avoiding creating meaningful privacy risks, while still ensuring that the product retains its usefulness to our users.</span></p>
<h3><span style="font-weight: 400;">8. Third-party scrutiny</span></h3>
<p><span style="font-weight: 400;">E2EE implies confidentiality even if the provider wants to access the contents of a communication. We aim for this to be verifiable externally, and, to this end, have published two white papers to provide transparency into our operations. We describe the properties of some features in our Help Center, and we encourage submissions to our <a href="https://www.facebook.com/whitehat" target="_blank" rel="noopener">bug bounty program</a>. Throughout the project, we have consulted with a diverse range of external parties to ensure that we’re making the right set of tradeoffs. To improve people’s ability to scrutinize us, we also support </span><a href="https://engineering.fb.com/2022/03/10/security/code-verify/" target="_blank" rel="noopener"><span style="font-weight: 400;">the Code Verify browser extension</span></a><span style="font-weight: 400;"> for our web-based end-to-end encrypted messaging, to give security researchers greater confidence that the code version that they are assessing is being used globally. </span></p>
<h2><span style="font-weight: 400;">High-level approach</span></h2>
<p><span style="font-weight: 400;">With all of this in mind, our high-level approach was to build off of Meta&#8217;s prior learnings in E2EE, from both <a href="https://engineering.fb.com/2021/09/10/security/whatsapp-e2ee-backups/" target="_blank" rel="noopener">WhatsApp</a> and Messenger’s Secret Conversations, and then to iterate on our most challenging problems. </span></p>
<p><span style="font-weight: 400;">Working from the baseline of these two approaches, we then had to address a series of significant technical challenges, including:</span></p>
<ol>
<li><span style="font-weight: 400;"><strong>Multi-device capability</strong>: Messenger’s model of multi-device reflects the Facebook network, which allows people to authenticate on new devices with a username and password, in order to send and receive messages. Since <a href="https://engineering.fb.com/2021/07/14/security/whatsapp-multi-device/" target="_blank" rel="noopener">WhatsApp’s multi-device capability</a> relies on a single primary device that must cryptographically authenticate companion devices, we adopted the Secret Conversations model of multi-device, while ensuring that it functions well for all of our users.</span></li>
<li><span style="font-weight: 400;"><strong>Feature support</strong>: Messenger has a number of messaging features that either don’t exist in WhatsApp, or function differently. Some of these just had to be rebuilt from scratch, while others required deploying new applied privacy technology. For example, we used </span><a href="https://datatracker.ietf.org/wg/ohai/about/" target="_blank" rel="noopener"><span style="font-weight: 400;">OHAI</span></a><span style="font-weight: 400;"> and </span><a href="https://engineering.fb.com/2022/03/30/security/de-identified-authentication-at-scale/" target="_blank" rel="noopener"><span style="font-weight: 400;">Anonymous Credentials</span></a><span style="font-weight: 400;"> to support searches of Facebook’s first-party sticker library, without revealing to us who is sending them.</span></li>
<li><span style="font-weight: 400;"><strong>Message history</strong>: Messenger has always allowed clients to operate off of a small stored local cache, relying on a server-side database for their message history. Neither WhatsApp nor Secret Conversations operated in this manner, and we didn’t want all users to have to rely on a device-side storage system. Instead, we designed an entirely new encrypted storage system called <a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf" target="_blank" rel="noopener">Labyrinth</a>, with ciphertexts uploaded to our servers and loaded on-demand by clients, while operating in a multi-device manner and supporting key rotation when clients are removed.</span></li>
<li><span style="font-weight: 400;"><strong>Web support</strong>: We needed to support E2EE within our existing web surfaces, including the main Facebook site. The Web platform carries significantly different constraints from native apps, meaning that we needed to take custom approaches to many different aspects of the product. Further, Web users often add and remove devices in very different patterns from mobile-only users, increasing the complexity of our multi-device challenge.</span></li>
</ol>
<h2><span style="font-weight: 400;">Learn more about E2EE on Messenger</span></h2>
<p><span style="font-weight: 400;">Today, we are sharing two white papers:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Our </span><a href="https://engineering.fb.com/wp-content/uploads/2023/12/MessengerEnd-to-EndEncryptionOverview_12-6-2023.pdf"><span style="font-weight: 400;">Messenger end-to-end encryption whitepaper</span></a><span style="font-weight: 400;">, which describes the core cryptographic protocol for transmitting messages between clients.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The </span><a href="https://engineering.fb.com/wp-content/uploads/2023/12/TheLabyrinthEncryptedMessageStorageProtocol_12-6-2023.pdf"><span style="font-weight: 400;">Labyrinth encrypted storage protocol whitepaper</span></a><span style="font-weight: 400;">, describing our protocol for end-to-end encrypting stored messages history between devices on a user’s account.</span></li>
</ul>
<p><span style="font-weight: 400;">These add to a number of publications that we have shared which cover Messenger’s E2EE, including:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Our recently updated </span><a href="https://messengernews.fb.com/wp-content/uploads/2021/12/Metas-approach-to-safer-private-messaging-on-Messenger-and-Instagram-DMs-Sep-23.pdf" target="_blank" rel="noopener"><span style="font-weight: 400;">Safety whitepaper</span></a></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The independent </span><a href="https://about.fb.com/news/2022/04/expanding-end-to-end-encryption-protects-fundamental-human-rights/" target="_blank" rel="noopener"><span style="font-weight: 400;">E2EE Human Rights Impact Assessment</span></a></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Our </span><a href="https://engineering.fb.com/wp-content/uploads/2022/07/Meta-Security-Principles-for-Private-Messaging-White-Paper-July-2022-2.pdf" target="_blank" rel="noopener"><span style="font-weight: 400;">Security Principles whitepaper</span></a></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The </span><a href="https://engineering.fb.com/2022/03/10/security/code-verify/" target="_blank" rel="noopener"><span style="font-weight: 400;">Code Verify browser extension</span></a></li>
</ul>
<h2><span style="font-weight: 400;">Beyond E2EE for Messenger</span></h2>
<p><span style="font-weight: 400;">The journey to bring E2EE to Messenger has been a long one, but it’s not yet finished. While we are globally launching default E2EE for personal one-to-one messages on Messenger, we are still in the testing phase for group messaging and some other products, like Instagram Direct Messages. On Instagram, we are currently testing “disappearing messages” for one-to-one Instagram Direct conversations in select countries. Disappearing messages are ephemeral and, as with those in Messenger, expire 24 hours after being sent. They are built leveraging our E2EE infrastructure and provide an increased level of privacy. We plan to expand this work as well as conduct additional testing around E2EE on Instagram over the next year.</span></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/12/06/security/building-end-to-end-security-for-messenger/">Building end-to-end security for Messenger</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20811</post-id>
        </item>
        <item>
            <title>Writing and linting Python at scale</title>
            <link>https://engineering.fb.com/2023/11/21/production-engineering/writing-linting-python-at-scale-meta/
            </link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Tue, 21 Nov 2023 17:00:59 +0000</pubDate>
            <category><![CDATA[Production Engineering]]></category>
            <category><![CDATA[meta tech podcast]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20803</guid>

            <description><![CDATA[<p>Python plays a big part at Meta. It powers Instagram’s backend and plays an important role in our configuration systems, as well as much of our AI work. Meta even made contributions to Python 3.12, the latest version of Python. On this episode of the Meta Tech Podcast, Meta engineer Pascal Hartig (@passy) is joined by Amethyst [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/11/21/production-engineering/writing-linting-python-at-scale-meta/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/21/production-engineering/writing-linting-python-at-scale-meta/">Writing and linting Python at scale</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<p>Python plays a big part at Meta. It powers <a href="https://engineering.fb.com/2023/08/15/developer-tools/immortal-objects-for-python-instagram-meta/">Instagram’s backend</a> and plays an important role in our configuration systems, as well as much of our <a href="https://ai.meta.com/tools/pytorch/">AI work</a>.</p>
<p>Meta even <a href="https://engineering.fb.com/2023/10/05/developer-tools/python-312-meta-new-features/">made contributions to Python 3.12</a>, the latest version of Python.</p>
<p>On this episode of the <a href="https://insidefacebookmobile.libsyn.com/55-what-its-like-to-ship-code-at-meta">Meta Tech Podcast</a>, Meta engineer Pascal Hartig (<a href="https://www.threads.net/@passy_">@passy</a>) is joined by Amethyst Reese, a production engineer at Meta, to discuss all things Python at Meta.</p>
<p>They discuss: how Meta’s Python Foundation Team works to improve the developer experience of everyone working with Python at Meta; <a href="https://engineering.fb.com/2023/08/07/developer-tools/fixit-2-linter-meta/">Fixit 2</a>, Meta’s recently open-sourced linter framework; and what exactly the role of production engineer at Meta entails.</p>
<p>For more from Amethyst, be sure to read her blog post: <a href="https://engineering.fb.com/2023/08/07/developer-tools/fixit-2-linter-meta/">Fixit 2: Meta’s next-generation auto-fixing linter</a></p>
<p>Download or listen to the episode below:</p>
<p><iframe loading="lazy" style="border: none;" title="Libsyn Player" src="//html5-player.libsyn.com/embed/episode/id/28464827/height/90/theme/custom/thumbnail/yes/direction/forward/render-playlist/no/custom-color/000000/" width="100%" height="90" scrolling="no" allowfullscreen="allowfullscreen"></iframe><br />
You can also listen to the episode wherever you get your podcasts:</p>
<p><a href="https://podcasts.apple.com/gb/podcast/inside-facebook-mobile/id1370910331?i=1000633126086">Apple Podcasts</a><br />
<a href="https://podcasts.google.com/feed/aHR0cHM6Ly9pbnNpZGVmYWNlYm9va21vYmlsZS5saWJzeW4uY29tL3Jzcw/episode/MTE1MjNkZWUtMDkwMi00MmRkLWI1NWYtYjQ2M2M0YmViMDEx?sa=X&amp;ved=0CAUQkfYCahcKEwjYqoyvwtOCAxUAAAAAHQAAAAAQCg">Google Podcasts</a><br />
<a href="https://open.spotify.com/episode/6mxBYXumYpQaRFrs9Z3SzA?si=LTxpyeYwSuC4CiFDjkeZWA">Spotify</a><br />
<a href="https://pca.st/A5tE">PocketCasts</a><br />
<a href="https://overcast.fm/login">Overcast</a><br />
<a href="https://castro.fm/itunes/1370910331">Castro</a></p>
<p>The <a href="https://insidefacebookmobile.libsyn.com/">Meta Tech Podcast</a> is a podcast, brought to you by Meta, where we highlight the work Meta’s engineers are doing at every level – from low-level frameworks to end-user features.</p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/21/production-engineering/writing-linting-python-at-scale-meta/">Writing and linting Python at scale</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20803</post-id>
        </item>
        <item>
            <title>Watch: Meta’s engineers on building network infrastructure for AI</title>
            <link>
                https://engineering.fb.com/2023/11/15/networking-traffic/watch-metas-engineers-on-building-network-infrastructure-for-ai/
            </link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Wed, 15 Nov 2023 17:00:16 +0000</pubDate>
            <category><![CDATA[ML Applications]]></category>
            <category><![CDATA[Networking & Traffic]]></category>
            <category><![CDATA[at scale conference]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20784</guid>

            <description><![CDATA[<p>Meta is building for the future of AI at every level &#8211; from hardware like MTIA v1, Meta’s first-generation AI inference accelerator to publicly released models like Llama 2, Meta’s next-generation large language model, as well as new generative AI (GenAI) tools like Code Llama. Delivering next-generation AI products and services at Meta’s scale also [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/11/15/networking-traffic/watch-metas-engineers-on-building-network-infrastructure-for-ai/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/15/networking-traffic/watch-metas-engineers-on-building-network-infrastructure-for-ai/">Watch: Meta’s engineers on building network infrastructure for AI</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<p><span style="font-weight: 400;">Meta is building for the future of AI at every level &#8211; from hardware like </span><a href="https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/"><span style="font-weight: 400;">MTIA v1</span></a><span style="font-weight: 400;">, Meta’s first-generation AI inference accelerator to publicly released models like </span><a href="https://ai.meta.com/llama/"><span style="font-weight: 400;">Llama 2</span></a><span style="font-weight: 400;">, Meta’s next-generation large language model, as well as new generative AI (GenAI) tools like </span><a href="https://about.fb.com/news/2023/08/code-llama-ai-for-coding/"><span style="font-weight: 400;">Code Llama</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">Delivering next-generation AI products and services at Meta’s scale also requires a next-generation infrastructure.</span></p>
<p><span style="font-weight: 400;">The 2023 edition of <a href="https://atscaleconference.com/" target="_blank" rel="noopener">Networking at Scale</a> focused on how Meta’s engineers and researchers have been designing and operating the network infrastructure over the last several years for Meta’s AI workloads, including our numerous ranking and recommendation workloads and the immense GenAI models. They cover a wide range of topics, including physical and logical network design, custom routing and load balancing solutions, performance tuning/debugging/benchmarking, and workload simulation and planning. We also look ahead to the requirements of GenAI models coming in the next several years. </span></p>
<h2><span style="font-weight: 400;">Networking for GenAI Training and Inference Clusters</span></h2>
<p><span style="font-weight: 400;">Jongsoo Park, Research Scientist, Infrastructure</span><span style="font-weight: 400;"><br />
</span><span style="font-weight: 400;">Petr Lapukhov, Network Engineer</span></p>
<p><span style="font-weight: 400;">Developing new GenAI technologies and incorporating them into product features is a top priority at Meta. But the sheer scale and complexity of GenAI models means new challenges for Meta’s network infrastructure.</span></p>
<p><span style="font-weight: 400;">Jongsoo Park and Petr Lapukhov discuss the unique requirements of new large language models, and how Meta’s infrastructure is changing for the new GenAI landscape.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=194847103485093"></div>
<h2><span style="font-weight: 400;">Meta’s Network Journey to Enable AI</span></h2>
<p><span style="font-weight: 400;">Hany Morsy, Network Engineer</span><span style="font-weight: 400;"><br />
</span><span style="font-weight: 400;">Susana Contrera, Network Engineer</span></p>
<p><span style="font-weight: 400;">Over the years, Meta&#8217;s AI infrastructure has transitioned from CPU-based to GPU-based training due to growing AI workloads. As a result, we have deployed large-scale, distributed, network-interconnected systems to support these systems and workloads. .</span></p>
<p><span style="font-weight: 400;">Today, our training models use a RoCE-based network fabric with a CLOS topology, where leaf switches are connected to GPU hosts and spine switches provide the Scale-Out connectivity to GPUs in the cluster.</span></p>
<p><span style="font-weight: 400;">Hany Morsy and Susana Contrera delve into how Meta’s network builds have evolved to support the needs of AI services. Along the way, they share challenges encountered, new solutions that were implemented, and the strategic considerations that have gone into building Meta’s high-performance, efficient network fabric for AI workloads.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=246184951206266"></div>
<h2><span style="font-weight: 400;">Scaling RoCE Networks for AI Training</span></h2>
<p><span style="font-weight: 400;">Adi Gangidi, Production Network Engineer</span></p>
<p><span style="font-weight: 400;">Adi Gangidi provides an overview of Meta&#8217;s RDMA deployment based on RoCEV2 transport for supporting our production AI training infrastructure. He sheds light on how Meta’s infrastructure is designed to both maximize the raw performance and consistency that is fundamental for AI-related workloads.</span></p>
<p><span style="font-weight: 400;">The talk also covers challenges in the routing, transport, and hardware layers that were solved along the way to scale Meta’s infrastructure, as well as opportunities for further progress over the next few years.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=788393819705307"></div>
<h2><span style="font-weight: 400;">Traffic Engineering for AI Training Networks</span></h2>
<p><span style="font-weight: 400;">Shuqiang Zhang, Software Engineer</span><span style="font-weight: 400;"><br />
</span><span style="font-weight: 400;">Jingyi Yang, Software Engineer</span></p>
<p><span style="font-weight: 400;">Meta has been operating RoCE-based distributed training clusters to serve its internal AI training workloads since 2020. But those early days saw challenges around maintaining job performance consistency.</span></p>
<p><span style="font-weight: 400;">Shuqiang Zhang and Jingyi Yang discuss centralized traffic engineering, one of Meta’s solutions to this challenge, which dynamically places traffic over all available paths in a load-balanced manner. They go over the centralized traffic engineering solution’s design, development, evaluation, and operational experience.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=506322838375599"></div>
<h2><span style="font-weight: 400;">Network Observability for AI/HPC Training Workflows</span></h2>
<p><span style="font-weight: 400;">Shengbao Zheng, Research Scientist</span></p>
<p><span style="font-weight: 400;">Having high-performance and reliable collective communication over Meta’s AI-Zone RDMA network is foundational for enabling and scaling Meta’s AI training and inference workloads. To facilitate this, it’s necessary to capture top-down observability from workload to network for collective communication &#8211; this allows us to attribute performance regression and training failures to the backend network when appropriate.</span></p>
<p><span style="font-weight: 400;">Meta has introduced two important tools for this: The ROCET and PARAM benchmarks and </span><a href="https://engineering.fb.com/2023/09/07/networking-traffic/chakra-execution-traces-benchmarking-network-performance-optimization/"><span style="font-weight: 400;">Chakra</span></a><span style="font-weight: 400;"> ecosystems. We build ROCET to associate the job to RDMA network metrics and provide analysis on top. In addition, we built the PARAM benchmark to allow for analyzing and tuning collective communication operations through workload trace. We recently shared these systems with the community via </span><a href="https://engineering.fb.com/2023/09/07/networking-traffic/chakra-execution-traces-benchmarking-network-performance-optimization/"><span style="font-weight: 400;">Chakra</span></a><span style="font-weight: 400;">, which allows for co-designing efficient distributed ML systems. In this talk, Shengbao Zheng discusses the design and use cases for these tools.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=237186149317741"></div>
<h2><span style="font-weight: 400;">Arcadia: End-to-end AI System Performance Simulator: Fostering data-driven decision-making processes and promoting the future evolution of AI systems</span></h2>
<p><span style="font-weight: 400;">Zhaodong Wang, Research Scientist</span><span style="font-weight: 400;"><br />
</span><span style="font-weight: 400;">Satyajeet Singh Ahuja, Networking Modeling and Optimization Engineer</span></p>
<p><a href="https://engineering.fb.com/2023/09/07/data-infrastructure/arcadia-end-to-end-ai-system-performance-simulator/"><span style="font-weight: 400;">Arcadia</span></a><span style="font-weight: 400;"> is a unified system designed to simulate the compute, memory, and network performance of AI training clusters. By providing a multi-disciplinary performance analysis framework, Arcadia aims to facilitate the design and optimization of various system levels, including application, network, and hardware.</span></p>
<p><span style="font-weight: 400;">With Arcadia, researchers and practitioners can gain valuable insights into the performance of future AI models and workloads on specific infrastructures and make data-driven decisions around how models and hardware will evolve in the future.</span></p>
<p><span style="font-weight: 400;">Arcadia allows Meta’s engineers to simulate the performance impact of scheduled operational tasks on AI-models that are running in production and helps them make job-aware decisions during day-to-day operational activity.</span></p>
<p><span style="font-weight: 400;">Zhaodong Wang and Satyajeet Singh Ahuja discuss Arcadia’s capabilities and its potential impact in advancing the field of AI systems and infrastructure.</span></p>
<div class="fb-video" data-allowfullscreen="true" data-href="https://www.facebook.com/watch/?v=636250121942307"></div>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/15/networking-traffic/watch-metas-engineers-on-building-network-infrastructure-for-ai/">Watch: Meta’s engineers on building network infrastructure for AI</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20784</post-id>
        </item>
        <item>
            <title>Enhancing the security of WhatsApp calls</title>
            <link>https://engineering.fb.com/2023/11/08/security/whatsapp-calls-enhancing-security/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Wed, 08 Nov 2023 14:00:29 +0000</pubDate>
            <category><![CDATA[Security]]></category>
            <category><![CDATA[WhatsApp]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20757</guid>

            <description><![CDATA[<p>New optional features in WhatsApp have helped make calling on WhatsApp more secure. “Silence Unknown Callers” is a new setting on WhatsApp that not only quiets annoying calls but also blocks sophisticated cyber attacks. “Protect IP Address in Calls” is a new setting on WhatsApp that helps hide your location from other parties on the [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/11/08/security/whatsapp-calls-enhancing-security/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/08/security/whatsapp-calls-enhancing-security/">Enhancing the security of WhatsApp calls</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">New optional features in WhatsApp have helped make calling on WhatsApp more secure.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Silence Unknown Callers” is a new setting on WhatsApp that not only quiets annoying calls but also blocks sophisticated cyber attacks.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Protect IP Address in Calls” is a new setting on WhatsApp that helps hide your location from other parties on the call.</span></li>
</ul>
<p><span style="font-weight: 400;">Privacy and security are at the core of WhatsApp. In addition to protecting personal messages with end-to-end encryption, WhatsApp empowers users to control their own privacy settings: from what you share, how you show up online, or who can reach out to you or add you to groups.</span></p>
<p><span style="font-weight: 400;">In June 2023, WhatsApp </span><span style="font-weight: 400;">announced</span><span style="font-weight: 400;"> an additional privacy feature: <a href="https://www.facebook.com/zuck/posts/pfbid02gH5Jfc6nYEAQacnCbYG2EZ3rkJB4A596EPYfoDKu6NcyeQ6evkWHZQbbtLfARhy3l" target="_blank" rel="noopener">Silence Unknown Callers.</a> We launched  this feature for the benefits it has for not only privacy but also security. The experience is simple: with the setting turned on, calls from unknown numbers do not ring your phone. Having carefully built this feature to minimize attack surface and external data processing, we are able to help protect users from not only unwanted contact, but also cyber attacks and spyware.</span></p>
<p><span style="font-weight: 400;">Then in October 2023, WhatsApp began rolling out “Protect IP Address in Calls” which hides your IP from the other party by relaying calls through WhatsApp Servers. </span></p>
<h2><span style="font-weight: 400;">Stop cyber attacks and hackers with “Silence Unknown Callers”</span></h2>
<p><span style="font-weight: 400;">Across the software industry, calling products are an attractive vector for cyber attacks. Popular software projects in this space, such as </span><a href="https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=webrtc" target="_blank" rel="noopener"><span style="font-weight: 400;">WebRTC</span></a><span style="font-weight: 400;"> and </span><a href="https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=pjsip" target="_blank" rel="noopener"><span style="font-weight: 400;">PJSIP</span></a><span style="font-weight: 400;">, have documented numerous vulnerabilities. Because of the complexity and large number of protocols involved, attackers have many opportunities to find a bug to exploit. Furthermore, calling software often automatically processes incoming packets from callers to optimize call setup and improve performance. This means calling vulnerabilities can often lead to “zero-click” attacks; the victim may not need to even accept the call for the attack to succeed.</span></p>
<figure id="attachment_20768" aria-describedby="caption-attachment-20768" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20768" src="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?w=1024" alt="" width="1024" height="448" srcset="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg 1921w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=916,401 916w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=768,336 768w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=1024,448 1024w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=1536,672 1536w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=96,42 96w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-1.jpg?resize=192,84 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20768" class="wp-caption-text">In most calling products, devices exchange information and setup state without user interaction.</figcaption></figure>
<p><span style="font-weight: 400;">Many calling products offer ways to silence calls. However, traditional methods of silencing retain the same network protocols and message flow of a normal call which merely silences the call on the recipient’s device. This leaves many risks for call recipients unmitigated.</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The recipient’s device may still perform complicated processing of attacker-controlled data</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">This gives an attacker ways to load data into the recipient’s memory </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">The recipient may leak device information back to the attacker to increase exploit delivery reliability</span></li>
</ul>
<p><span style="font-weight: 400;">One could attempt to mitigate these risks by adding state machines, firewalls, and sandboxes on the recipient. However, there are </span><a href="https://citizenlab.ca/2023/04/nso-groups-pegasus-spyware-returns-in-2022/" target="_blank" rel="noopener"><span style="font-weight: 400;">many</span> <span style="font-weight: 400;">examples</span></a><span style="font-weight: 400;"> in the industry of these techniques <a href="https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2020/CVE-2020-6572.html" target="_blank" rel="noopener">failing to protect users</a>.</span></p>
<p><span style="font-weight: 400;">Instead, WhatsApp built a specialized protocol for delivering stripped-down, silenced call notifications to recipients. The server enforces this protocol, protecting the recipient device from the complexity of normal call setup and from processing attacker-controlled data.</span></p>
<figure id="attachment_20769" aria-describedby="caption-attachment-20769" style="width: 1024px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20769" src="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?w=1024" alt="" width="1024" height="448" srcset="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg 1921w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=916,401 916w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=768,336 768w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=1024,448 1024w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=1536,672 1536w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=96,42 96w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-2.jpg?resize=192,84 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20769" class="wp-caption-text">Our implementation of silenced calls, with WhatsApp servers enforcing separation.</figcaption></figure>
<p><span style="font-weight: 400;">This approach took more effort than a client-only method. How can the server know if the call should be silenced without asking the recipient? In end-to-end encrypted messengers like WhatsApp, clients are the source of truth. We don’t keep logs of who everyone is messaging or calling: While traditionally mobile carriers and operators store this information, we believe that keeping these records for two billion users would be both a privacy and security risk and we don’t do it. </span></p>
<p><span style="font-weight: 400;">WhatsApp developed a new technology, named privacy tokens, to solve this problem. Each client locally decides which other user it trusts and distributes tokens to them. When a call is placed, the caller includes the privacy token of the recipient in the protocol message. Next, the server checks the token’s validity along with a few other factors to determine if the intended recipient allows this sender to ring them. Crucially, for our user’s privacy, the server does not learn anything about the exact relationship between the caller and the recipient from the token.</span></p>
<p><span style="font-weight: 400;">With our design of this feature, calling becomes a much less attractive vector for attackers.</span></p>
<h2><span style="font-weight: 400;">Protect your IP address metadata in calls</span></h2>
<figure id="attachment_20770" aria-describedby="caption-attachment-20770" style="width: 863px" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-large wp-image-20770" src="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-3.png?w=863" alt="" width="863" height="550" srcset="https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-3.png 863w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-3.png?resize=768,489 768w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-3.png?resize=96,61 96w, https://engineering.fb.com/wp-content/uploads/2023/11/WhatsApp-Calls_image-3.png?resize=192,122 192w" sizes="(max-width: 992px) 100vw, 62vw" /><figcaption id="caption-attachment-20770" class="wp-caption-text">Two common methods of connecting call participants: peer-to-peer and via a relay.</figcaption></figure>
<p><span style="font-weight: 400;">Most calling products people use today have peer-to-peer connections between participants. This direct connection allows for faster data transfers and better call quality, but it also means that participants need to know each other&#8217;s IP addresses so that call data packets can be delivered to the correct device – meaning that the IP addresses are visible to both callers on a 1:1 call. IP addresses may contain information that some of our most privacy-conscious users are mindful of, such as broad geographical location or internet provider.</span></p>
<p><span style="font-weight: 400;">To address this concern, we introduced a new feature on WhatsApp that allows you to protect your IP address during calls. With this feature enabled, all your calls will be relayed through WhatsApp&#8217;s servers, ensuring that other parties in the call cannot see your IP address and subsequently deduce your general geographical location. This new feature provides an additional layer of privacy and security particularly geared towards our most privacy-conscious users. As always, your calls are end-to-end encrypted, so even if a call is relayed through WhatsApp servers, WhatsApp cannot listen to your calls.</span></p>
<p><span style="font-weight: 400;">Visit the <a href="https://faq.whatsapp.com/2635108359972899/" target="_blank" rel="noopener">WhatsApp Help Center</a> learn more about this feature &#8211; which is being rolled out currently to iOS and Android users &#8211; and <a href="https://faq.whatsapp.com/2635108359972899/" target="_blank" rel="noopener">how to activate it</a>.</span></p>
<h2><span style="font-weight: 400;">Conclusion</span></h2>
<p><span style="font-weight: 400;">WhatsApp built and launched “Silence Unknown Callers” and “Protect IP Address in Calls” this year as part of our ongoing comprehensive work to keep users safe. These features respect and improve user privacy while also reducing the effectiveness of real-world attacks.</span></p>
<p><span style="font-weight: 400;">Protecting user privacy and security is absolutely necessary for WhatsApp to accomplish its mission to enable private communication for the world. These new security features combine with many other protections to keep people safe on WhatsApp.</span></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/08/security/whatsapp-calls-enhancing-security/">Enhancing the security of WhatsApp calls</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20757</post-id>
        </item>
        <item>
            <title>How Meta built Threads in 5 months</title>
            <link>https://engineering.fb.com/2023/11/06/android/how-meta-built-threads-in-5-months/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Mon, 06 Nov 2023 17:00:26 +0000</pubDate>
            <category><![CDATA[Android]]></category>
            <category><![CDATA[Culture]]></category>
            <category><![CDATA[iOS]]></category>
            <category><![CDATA[Web]]></category>
            <category><![CDATA[meta tech podcast]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20726</guid>

            <description><![CDATA[<p>In about five short months, a small team of engineers at Meta took Threads, the new text-based conversations app, from from an idea to the most successful app launch of all time, pulling in over 100M users in its first five days. But this achievement wouldn&#8217;t have been possible without Meta&#8217;s existing systems and infrastructure. [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/11/06/android/how-meta-built-threads-in-5-months/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/06/android/how-meta-built-threads-in-5-months/">How Meta built Threads in 5 months</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<p dir="ltr">In about five short months, a small team of engineers at Meta took Threads, the new text-based conversations app, from from an idea to the most successful app launch of all time, pulling in over 100M users in its first five days.</p>
<p dir="ltr">But this achievement wouldn&#8217;t have been possible without Meta&#8217;s existing systems and infrastructure.</p>
<p dir="ltr">On the latest episode of the <a href="https://insidefacebookmobile.libsyn.com/55-what-its-like-to-ship-code-at-meta" target="_blank" rel="noopener">Meta Tech Podcast</a>, Meta engineer Pascal Hartig (<a href="https://www.threads.net/@passy_" target="_blank" rel="noopener">@passy</a>) is joined by <span class="xt0psk2">Joy Qiu</span>, <span class="xt0psk2">Cameron Roth,</span> and <span class="xt0psk2">Richard Zadorozny, </span>three engineers from the Threads team, who worked on backend, iOS, and Android respectively.</p>
<p dir="ltr">Learn more of the <a href="https://engineering.fb.com/2023/09/07/culture/threads-inside-story-metas-newest-social-app/" target="_blank" rel="noopener">inside story behind Threads</a> and the challenges their team faced along the way.</p>
<p dir="ltr">Download or listen to the episode below:</p>
<p><iframe loading="lazy" style="border: none;" title="Libsyn Player" src="//html5-player.libsyn.com/embed/episode/id/28176350/height/90/theme/custom/thumbnail/yes/direction/forward/render-playlist/no/custom-color/000000/" width="100%" height="90" scrolling="no" allowfullscreen="allowfullscreen"></iframe></p>
<div class="x1e56ztr xisnujt"></div>
<div>You can also listen to the episode wherever you get your podcasts:</div>
<div></div>
<ul class="x1e56ztr x1xmf6yo x1xfsgkm xtaz4m5">
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://podcasts.apple.com/gb/podcast/how-threads-was-built-in-5-months/id1370910331?i=1000629665567" target="_blank" rel="nofollow noopener noreferrer">Apple Podcasts</a></span></div>
</li>
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://podcasts.google.com/feed/aHR0cHM6Ly9pbnNpZGVmYWNlYm9va21vYmlsZS5saWJzeW4uY29tL3Jzcw/episode/NDg1ODVlMDYtNTA3ZS00MjgxLWFhNzQtNTg3ZjYxOTU4NTk0?sa=X&amp;ved=0CAUQkfYCahcKEwjAoK6XkY2CAxUAAAAAHQAAAAAQVA" target="_blank" rel="nofollow noopener noreferrer">Google Podcasts</a></span></div>
</li>
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://open.spotify.com/episode/6diVhRe1yia7bmTcnR0LEx" target="_blank" rel="nofollow noopener noreferrer">Spotify</a></span></div>
</li>
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://pca.st/7kuzug0v" target="_blank" rel="nofollow noopener noreferrer">PocketCasts</a></span></div>
</li>
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://overcast.fm/login" target="_blank" rel="nofollow noopener noreferrer">Overcast</a></span></div>
</li>
<li>
<div class="x1e56ztr xisnujt"><span class="x193iq5w xeuugli x13faqbe x1vvkbs x1xmvt09 x6prxxf xvq8zen xo1l8bm xzsf02u"><a class="x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz x1fey0fg" tabindex="0" role="link" href="https://castro.fm/itunes/1370910331" target="_blank" rel="nofollow noopener noreferrer">Castro</a></span></div>
</li>
</ul>
<p>The <a href="https://insidefacebookmobile.libsyn.com/" target="_blank" rel="noopener">Meta Tech Podcast</a> is a podcast, brought to you by Meta, where we highlight the work Meta&#8217;s engineers are doing at every level – from low-level frameworks to end-user features.</p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/11/06/android/how-meta-built-threads-in-5-months/">How Meta built Threads in 5 months</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20726</post-id>
        </item>
        <item>
            <title>Automating data removal</title>
            <link>https://engineering.fb.com/2023/10/31/data-infrastructure/automating-data-removal/</link>

            <dc:creator><![CDATA[]]></dc:creator>
            <pubDate>Tue, 31 Oct 2023 16:00:29 +0000</pubDate>
            <category><![CDATA[Data Infrastructure]]></category>
            <guid isPermaLink="false">https://engineering.fb.com/?p=20731</guid>

            <description><![CDATA[<p>Meta’s Systematic Code and Asset Removal Framework (SCARF) has a subsystem for identifying and removing unused data types. SCARF scans production data systems to identify tables or assets that are unused and safely removes them. SCARF avoids tedious manual work and ensures that product data is correctly removed when a product is shut down. This [...]</p>
<p><a class="btn btn-secondary understrap-read-more-link" href="https://engineering.fb.com/2023/10/31/data-infrastructure/automating-data-removal/">Read More...</a></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/10/31/data-infrastructure/automating-data-removal/">Automating data removal</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></description>
            <content:encoded><![CDATA[<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Meta’s Systematic Code and Asset Removal Framework (SCARF) has a subsystem for identifying and removing unused data types.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">SCARF scans production data systems to identify tables or assets that are unused and safely removes them.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">SCARF avoids tedious manual work and ensures that product data is correctly removed when a product is shut down.</span></li>
</ul>
<p><span style="font-weight: 400;">This is the third and final post in our series on Meta&#8217;s Systematic Code and Asset Removal Framework (SCARF). SCARF contains a combination of subsystems that analyze code and data usage throughout Meta to aid in the safe and efficient removal of deprecated products. In our first post on </span><a href="https://engineering.fb.com/2023/10/17/data-infrastructure/automating-product-deprecation-meta/"><span style="font-weight: 400;">automating product deprecation</span></a><span style="font-weight: 400;">, we discussed the complexities of product deprecations and introduced SCARF&#8217;s workflow management tools that guide engineers through a coordinated process to safely deprecate products. In the second post on </span><a href="https://engineering.fb.com/2023/10/24/data-infrastructure/automating-dead-code-cleanup/"><span style="font-weight: 400;">automating dead code cleanup</span></a><span style="font-weight: 400;">, we discussed SCARF&#8217;s dead code subsystem and its ability to analyze both static and dynamic usage of code to automatically generate change requests to remove unused code. Throughout this series, we have referred to the example of the deprecation of a </span><a href="https://about.fb.com/news/2015/06/introducing-moments/"><span style="font-weight: 400;">photo sharing app called Moments</span></a><span style="font-weight: 400;">, which Meta launched in 2015 and eventually shut down in 2019.</span></p>
<p><span style="font-weight: 400;">In this post, we introduce the subsystem responsible for automating the identification and safe removal of unused data types at Meta. This process can be unexpectedly difficult, because large software systems are inevitably interconnected. Moments relied on several pieces of shared Facebook functionality and infrastructure, and deleting it was more complicated than simply turning off servers and removing data tables.</span></p>
<h2><span style="font-weight: 400;">Unused data cleanup</span></h2>
<p><span style="font-weight: 400;">SCARF implements an unused data type cleanup system for Meta engineers to leverage when they want to ensure consistent removal of unused data. SCARF scans data systems to identify each type of data stored (for example, identifying all the tables in a relational database) and, for each of these, determines whether the data is being used. If any of the assets are not in use, SCARF initiates a process to safely remove them.</span></p>
<p><span style="font-weight: 400;">The types of data tracked by SCARF vary and include things like database tables, partitioned &#8220;use cases&#8221; in shared storage systems, or object classes. Each represents a class of data — not individual records. Meta has a separate system, </span><a href="https://engineering.fb.com/2020/08/12/security/delf/"><span style="font-weight: 400;">DELF</span></a><span style="font-weight: 400;">, for deleting individual records, rows, and objects.</span></p>
<p><span style="font-weight: 400;">SCARF coordinates several kinds of tasks for each data system: metadata collection (e.g., data quantity, field types), usage collection, analysis, and actions. These tasks share some common components and adhere to a standardized format; however, the implementation is inherently specific to each supported data system.</span></p>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20732" src="https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?w=1020" alt="" width="1020" height="1024" srcset="https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png 1456w, https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?resize=912,916 912w, https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?resize=768,771 768w, https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?resize=1020,1024 1020w, https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?resize=96,96 96w, https://engineering.fb.com/wp-content/uploads/2023/10/Automating-Data-Removal-image1.png?resize=192,193 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<h2><span style="font-weight: 400;">Measuring usage</span></h2>
<p><span style="font-weight: 400;">SCARF tracks two primary metrics to determine if deletion is safe: It measures static usage by identifying code that appears to query a type of data; and it measures runtime usage by observing access patterns in production.</span></p>
<p><span style="font-weight: 400;">As mentioned in our blog post, </span><a href="https://engineering.fb.com/2023/10/24/data-infrastructure/automating-dead-code-cleanup/"><span style="font-weight: 400;">Automating dead code cleanup</span></a><span style="font-weight: 400;">, SCARF statically analyzes Meta’s codebases using</span><a href="https://glean.software/"> <span style="font-weight: 400;">Glean</span></a><span style="font-weight: 400;">. Glean presents static analysis facts extracted from the compiler in an indexed, standardized format. SCARF queries Glean to locate code that appears to reference each type of data. For example, each type of data stored in Meta&#8217;s object graph data system</span><a href="https://engineering.fb.com/2013/06/25/core-data/tao-the-power-of-the-graph/"> <span style="font-weight: 400;">TAO</span></a><span style="font-weight: 400;"> is referenced by an enum value: We can locate usages of each enum value in code across multiple languages.</span></p>
<pre class="line-numbers"><code class="language-python">viewed_photo = TAO.fetch(
    id=objectId,
    type=TAOType.USER_VIEWED_PHOTO,
)
</code></pre>
<p><span style="font-weight: 400;">SCARF also measures the usage of each type of data at runtime. We instrument Meta’s data systems to publish counters indicating how many reads each type of data has received from relevant sources, like production traffic from our webserver fleet, while ignoring traffic created by backup infrastructure.</span></p>
<p><span style="font-weight: 400;">Some of our data systems, like </span><a href="https://engineering.fb.com/2013/06/25/core-data/tao-the-power-of-the-graph/"><span style="font-weight: 400;">TAO</span></a><span style="font-weight: 400;">, receive </span><a href="https://engineering.fb.com/2013/06/25/core-data/tao-the-power-of-the-graph/"><span style="font-weight: 400;">billions of requests per second</span></a><span style="font-weight: 400;">. Instrumenting a data system at that scale, while ensuring we only measure certain types of usage, presents complex engineering challenges to avoid costly performance degradations.</span></p>
<h2><span style="font-weight: 400;">Orchestrating removal</span></h2>
<p><span style="font-weight: 400;">Once SCARF detects that a type of data is completely unused by combining the signals from our metadata, traffic analysis, and code references, it notifies the engineering team responsible for that data type, via an internal ticket, that cleanup will proceed . </span></p>
<p><span style="font-weight: 400;">After a configured time, SCARF blocks all reads and writes via a data system specific mechanism. This period of time is important as it acts as a dry run of what would happen when the data is truly deleted. Once this period elapses, the data will be deleted. The system keeps an internal log of actions it has performed for our records. </span></p>
<p><span style="font-weight: 400;">For example, if a type of data in TAO has no code references or production traffic, after a notification and waiting to see if there are objections, SCARF will instruct TAO to raise an error any time a service attempts to read from or write to that type of data. After a further monitoring phase, it will instruct TAO to delete the data.</span></p>
<p><img loading="lazy" decoding="async" class="alignnone size-large wp-image-20737" src="https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?w=1024" alt="Automating Data Removal" width="1024" height="831" srcset="https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png 1178w, https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?resize=916,743 916w, https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?resize=768,623 768w, https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?resize=1024,831 1024w, https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?resize=96,78 96w, https://engineering.fb.com/wp-content/uploads/2023/10/395346664_898690634945541_3105998864531236434_n.png?resize=192,156 192w" sizes="(max-width: 992px) 100vw, 62vw" /></p>
<p><span style="font-weight: 400;">Note that SCARF does not wait for the engineer’s acknowledgement when the internal ticket is filed – the system biases towards the automatic removal of unused data types and relies on its thorough analyses to ensure that only unused data is removed. If something is unused for long enough, it is less and less likely that problems will arise when automation cleans it up. Biassing towards automation improves efficiency and allows the system to scale beyond a process that requires manual approvals for every action. </span></p>
<p><span style="font-weight: 400;">Should a mistake be made, the access restriction period acts as a buffer where any mistakes can be caught before any data deletion occurs and our analysis can be updated to account for any missing signals. In the worst case, if data is deleted but should not have been, many systems at Meta provide backups to protect against data loss; and while the backups are available, they can act as a final safeguard to protect against erroneous deletions. </span></p>
<p><span style="font-weight: 400;">Engineers can interact with SCARF&#8217;s deletion process in various ways. As </span><a href="https://engineering.fb.com/2023/10/17/data-infrastructure/automating-product-deprecation-meta/"><span style="font-weight: 400;">mentioned earlier</span></a><span style="font-weight: 400;">, they can override the usage signals that SCARF detects in order to proceed with the deletion, if they determine those signals to be false-positives. They can also accelerate the process by shortening the waiting periods. Finally, engineers can highlight problems they have noticed back to our team who build SCARF itself: Often engineers will notice false-positives (cases when SCARF detects something as used, but it isn’t), and rarely false-negatives (when SCARF detects no usage, but there actually is usage), in the usage signals collected by SCARF.</span></p>
<h2><span style="font-weight: 400;">Coping with cross-system dependencies</span></h2>
<p><span style="font-weight: 400;">Meta has many different systems for storing data, many of which are specialized for a certain use-case. A high-quality product will often require the features of multiple different data systems. For example, TAO is a graph database that excels at serving many small, fast queries, but it wouldn’t be used for tasks like machine learning, ranking, or aggregation. As such, Meta frequently leverages multiple data storage systems for a single product, including data pipelines that move data between systems. SCARF hence has to understand the interconnections between these systems to ensure data is removed from each place it is stored and to prevent deletions from occurring out of order. </span></p>
<p><span style="font-weight: 400;">SCARF models these through a curated set of generated asset relationships. For a given asset and its corresponding inbound and outbound dependencies, SCARF determines the nature of the relationship, which dictates which asset must be deleted first and whether the deletion of one asset necessitates the deletion of the other. For example, some assets exist solely as the result of moving data between systems and must be removed together in a multi-step process. This modeling of system relationships within SCARF enables more thorough orchestration of data cleanup and prevents the system from attempting to delete assets out of order.</span></p>
<h2><span style="font-weight: 400;">Coping with code usage</span></h2>
<p><span style="font-weight: 400;">Thinking of Meta’s code and data definitions as a single dependency graph, SCARF can be seen as a system that prunes leaves and isolated nodes in this graph. This dependency graph changes over time, as new nodes and edges come and go with every piece of engineering work.</span></p>
<p><span style="font-weight: 400;">SCARF is unable to automatically remove data if it identifies code that could use this data, even if that code is not being run: SCARF, by design, will not break edges in this graph. For example, if an engineer commits a script referencing a type of data in TAO for debugging purposes, SCARF would correctly identify that as a reference to the use case and prevent deletion — even if the script is no longer used.</span></p>
<p><span style="font-weight: 400;">As mentioned in </span><a href="https://engineering.fb.com/2023/10/24/data-infrastructure/automating-dead-code-cleanup/"><span style="font-weight: 400;">part two of this series</span></a><span style="font-weight: 400;">, SCARF&#8217;s dead code subsystem works to help solve this problem through the automated removal of known dead code. If the dead code system is able to remove the unused script, the unused data can then be removed.</span></p>
<h2><span style="font-weight: 400;">Removing data at scale</span></h2>
<p><span style="font-weight: 400;">Removing unused data types not only simplifies our internal infrastructure, but also saves material capacity costs. In the last year, it has removed petabytes of unused data, across </span><span style="font-weight: 400;">12.8M</span><span style="font-weight: 400;"> different data types stored in 21 different data systems. While, in many products, an individual piece of data may consist of an identifier (primary key) and a small amount of data, at Meta&#8217;s scale there are billions of such rows. Data logged during routine usage of our services to provide analytics, operational logging, or analysis will also consist of billions of rows, multiplied by the retention of historical data in our warehouse, and our backups. </span></p>
<p><span style="font-weight: 400;">SCARF concurrently operates on millions of assets each day and drastically reduces the overhead on our teams from having to manually intervene and clean up unused data. The team that maintains SCARF has developed strong partnerships with our colleagues that build and maintain these various data systems to leverage their expertise and to work together to provide the APIs that SCARF invokes to safely restrict access to and eventually clean up data. </span></p>
<p><span style="font-weight: 400;">SCARF runs on a daily cadence: The lifecycle of products and features means that there are new types of data being created every day as well as types of data that become unused every day. Running the system regularly ensures that as the final references to assets are deleted, SCARF picks up these changes quickly and can trigger the relevant automation.</span></p>
<h2><span style="font-weight: 400;">A summary of SCARF</span></h2>
<p><span style="font-weight: 400;">SCARF provides a powerful suite of tools to the company&#8217;s engineering teams. Its workflow management tooling powers thousands of human-led deprecation projects alongside the millions of code and data assets it has cleaned automatically.</span></p>
<p><span style="font-weight: 400;">SCARF also serves useful purposes for Meta’s privacy teams: We can use the tool to monitor the progress of ongoing product deprecations and ensure that they are completed in a timely manner. When there’s work that our automation is unable to do, SCARF’s internal tooling educates engineers about what they need to do and how to do it safely. The information it provides is not generic: It is tailored to the specific code and data that an engineer is deleting, empowering them to make the right decisions in the most efficient manner. </span></p>
<p><span style="font-weight: 400;">By discussing privacy innovations like SCARF, we hope to create transparency about our continuous investment in infrastructure that delivers privacy protections for the people that use our products and services. Our dedication to automating and orchestrating unused code and data deletion in a comprehensive manner is just one example of the substantive privacy by design measures we focus on at Meta. </span></p>
<p><span style="font-weight: 400;">Product deprecation can be safe, efficient, and thorough, even with infrastructure as complex and vast as Meta’s. Combining automation with engineering tooling is a tried and tested strategy that we have found to be very effective. We are investing in this space for the long-term since product deprecation is a continuous part of the data lifecycle, which contributes to the sustained success of any large tech company like Meta.</span></p>
<p>The post <a rel="nofollow" href="https://engineering.fb.com/2023/10/31/data-infrastructure/automating-data-removal/">Automating data removal</a> appeared first on <a rel="nofollow" href="https://engineering.fb.com">Engineering at Meta</a>.</p>
]]></content:encoded>


            <post-id xmlns="com-wordpress:feed-additions:1">20731</post-id>
        </item>
    </channel>
</rss>